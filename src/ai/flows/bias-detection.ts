// This is an autogenerated file from Firebase Studio.
'use server';
/**
 * @fileOverview Detects and highlights potentially biased language in text with a confidence score.
 *
 * - detectBiasInText - A function that analyzes text for bias.
 * - DetectBiasInTextInput - The input type for the detectBiasInText function.
 * - DetectBiasInTextOutput - The return type for the detectBiasInText function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';

const DetectBiasInTextInputSchema = z.object({
  text: z.string().describe('The input text to analyze for bias.'),
});
export type DetectBiasInTextInput = z.infer<typeof DetectBiasInTextInputSchema>;

const BiasDetectionResultSchema = z.object({
  biasType: z.string().describe('The type of bias detected (e.g., gender, racial, ableist).'),
  biasedPhrase: z.string().describe('The specific phrase identified as biased.'),
  confidenceScore: z.number().describe('A confidence score (0-1) indicating the likelihood of bias.'),
  suggestedRewrite: z.string().describe('A suggested unbiased rephrasing of the biased phrase.'),
});

const DetectBiasInTextOutputSchema = z.object({
  overallBiasScore: z.number().describe('An overall score (0-1) indicating the level of bias in the text'),
  biasDetections: z.array(BiasDetectionResultSchema).describe('An array of bias detection results.'),
});

export type DetectBiasInTextOutput = z.infer<typeof DetectBiasInTextOutputSchema>;

export async function detectBiasInText(input: DetectBiasInTextInput): Promise<DetectBiasInTextOutput> {
  return detectBiasInTextFlow(input);
}

const detectBiasInTextPrompt = ai.definePrompt({
  name: 'detectBiasInTextPrompt',
  input: {schema: DetectBiasInTextInputSchema},
  output: {schema: DetectBiasInTextOutputSchema},
  prompt: `You are an AI expert in identifying biased language. Analyze the provided text for potential biases, including but not limited to gender, racial, ableist, and other harmful patterns. 

For each instance of bias detected, provide:
- biasType: The specific type of bias (e.g., gender bias, racial bias).
- biasedPhrase: The exact phrase that exhibits bias.
- confidenceScore: A confidence score between 0 and 1, indicating the likelihood of bias.
- suggestedRewrite: An unbiased alternative phrasing.

Text: {{{text}}}

Output should be structured as a JSON object with an overallBiasScore from 0-1 and an array of biasDetections.`,
});

const detectBiasInTextFlow = ai.defineFlow(
  {
    name: 'detectBiasInTextFlow',
    inputSchema: DetectBiasInTextInputSchema,
    outputSchema: DetectBiasInTextOutputSchema,
  },
  async input => {
    const {output} = await detectBiasInTextPrompt(input);
    return output!;
  }
);
